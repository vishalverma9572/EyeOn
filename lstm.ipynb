{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'label_processor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mm:\\mask\\lstm.ipynb Cell 1\u001b[0m in \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/mask/lstm.ipynb#W0sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m sequence_model\n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/mask/lstm.ipynb#W0sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# Load the model from the last checkpoint\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/m%3A/mask/lstm.ipynb#W0sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m sequence_model \u001b[39m=\u001b[39m load_model_from_checkpoint()\n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/mask/lstm.ipynb#W0sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# Save the model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/mask/lstm.ipynb#W0sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m sequence_model\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39msaved_model\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mm:\\mask\\lstm.ipynb Cell 1\u001b[0m in \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/mask/lstm.ipynb#W0sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_model_from_checkpoint\u001b[39m():\n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/mask/lstm.ipynb#W0sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39m# Load the model architecture\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/m%3A/mask/lstm.ipynb#W0sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     sequence_model \u001b[39m=\u001b[39m get_sequence_model()\n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/mask/lstm.ipynb#W0sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39m# Load the weights from the last checkpoint\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/mask/lstm.ipynb#W0sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     latest_checkpoint \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mtrain\u001b[39m.\u001b[39mlatest_checkpoint(checkpoint_dir)\n",
      "\u001b[1;32mm:\\mask\\lstm.ipynb Cell 1\u001b[0m in \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/m%3A/mask/lstm.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_sequence_model\u001b[39m(): \n\u001b[1;32m----> <a href='vscode-notebook-cell:/m%3A/mask/lstm.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     class_vocab \u001b[39m=\u001b[39m label_processor\u001b[39m.\u001b[39mget_vocabulary()\n\u001b[0;32m      <a href='vscode-notebook-cell:/m%3A/mask/lstm.ipynb#W0sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     frame_features_input \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mInput((MAX_SEQ_LENGTH, NUM_FEATURES))\n\u001b[0;32m      <a href='vscode-notebook-cell:/m%3A/mask/lstm.ipynb#W0sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     mask_input \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mInput((MAX_SEQ_LENGTH,), dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbool\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'label_processor' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Define the function to create the sequence model\n",
    "def get_sequence_model(): \n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "\n",
    "    frame_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n",
    "    mask_input = keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "\n",
    "    # Refer to the following tutorial to understand the significance of using `mask`:\n",
    "    # https://keras.io/api/layers/recurrent_layers/gru/\n",
    "    x = keras.layers.GRU(16, return_sequences=True)(frame_features_input, mask=mask_input)\n",
    "    x = keras.layers.GRU(8)(x)\n",
    "    x = keras.layers.Dropout(0.4)(x)\n",
    "    x = keras.layers.Dense(8, activation=\"relu\")(x)\n",
    "    output = keras.layers.Dense(len(class_vocab), activation=\"softmax\")(x)\n",
    "\n",
    "    rnn_model = keras.Model([frame_features_input, mask_input], output)\n",
    "\n",
    "    rnn_model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return rnn_model\n",
    "\n",
    "# Define the directory where the model and its checkpoints are saved\n",
    "checkpoint_dir = \"./detect/lstm/\"\n",
    "\n",
    "# Define the function to load the model from the last checkpoint\n",
    "def load_model_from_checkpoint():\n",
    "    # Load the model architecture\n",
    "    sequence_model = get_sequence_model()\n",
    "    \n",
    "    # Load the weights from the last checkpoint\n",
    "    latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "    sequence_model.load_weights(latest_checkpoint)\n",
    "    \n",
    "    return sequence_model\n",
    "\n",
    "# Load the model from the last checkpoint\n",
    "sequence_model = load_model_from_checkpoint()\n",
    "\n",
    "# Save the model\n",
    "sequence_model.save(\"saved_model\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
